#!/usr/bin/env python3
"""
Multi-Agent Configuration
Integrates multiple specialized person agents into the LiveKit voice agent
"""

import logging
from typing import Literal, Optional
from pydantic import BaseModel, Field

from livekit.agents import llm
from livekit.agents.voice import Agent
from livekit.agents.llm import function_tool
from livekit.plugins import silero

# Import multi-agent RAG service
import sys
from pathlib import Path

# Add parent directory to path
backend_src = Path(__file__).parent.parent
if str(backend_src) not in sys.path:
    sys.path.insert(0, str(backend_src))

from rag.multi_agent_rag_service import get_multi_agent_rag_service

logger = logging.getLogger(__name__)


# ============================================================================
# Pydantic Configuration Models (keeping existing structure)
# ============================================================================

class STTConfig(BaseModel):
    """STT (Speech-to-Text) Configuration"""
    
    model: str = Field(
        default="assemblyai/universal-streaming",
        description="STT model identifier"
    )


class LLMConfig(BaseModel):
    """LLM (Large Language Model) Configuration"""
    
    model: str = Field(
        default="openai/gpt-4o-mini",
        description="LLM model identifier"
    )
    
    instructions: str = Field(
        default="""You are part of a networking event simulation with multiple specialized experts.
        
Your role is to facilitate natural conversations and route questions to the appropriate expert.
When a user asks a question, you will have access to specialized person agents who each have deep knowledge in their specific topic area.

Key guidelines:
- Be natural and conversational as if you're at a real networking event
- Each expert has their own personality and backstory - respect that
- When answering questions, incorporate the context provided from the expert's knowledge base
- Handle handoffs smoothly when redirecting to another expert
- Stay in character with the current expert's personality
""",
        description="System instructions for multi-agent coordination"
    )


class TTSConfig(BaseModel):
    """TTS (Text-to-Speech) Configuration"""
    
    model: str = Field(
        default="cartesia/sonic-3:a167e0f3-df7e-4d52-a9c3-f949145efdab",
        description="TTS model identifier"
    )


class VADConfig(BaseModel):
    """VAD (Voice Activity Detection) Configuration"""
    
    min_speech_duration: float = Field(default=0.1, ge=0.05, le=1.0)
    min_silence_duration: float = Field(default=0.6, ge=0.1, le=2.0)
    activation_threshold: float = Field(default=0.5, ge=0.0, le=1.0)


class SessionConfig(BaseModel):
    """Agent Session Configuration"""
    
    turn_detection: Literal["vad", "stt", "realtime_llm", "manual"] = Field(default="vad")
    preemptive_generation: bool = Field(default=True)
    allow_interruptions: bool = Field(default=True)
    min_endpointing_delay: float = Field(default=0.5, ge=0.0)
    max_endpointing_delay: float = Field(default=3.0, ge=0.0)


class AgentConfig(BaseModel):
    """Complete Agent Configuration"""
    
    stt: STTConfig = Field(default_factory=STTConfig)
    llm: LLMConfig = Field(default_factory=LLMConfig)
    tts: TTSConfig = Field(default_factory=TTSConfig)
    vad: VADConfig = Field(default_factory=VADConfig)
    session: SessionConfig = Field(default_factory=SessionConfig)
    greeting_message: str = Field(
        default="",  # Will be dynamically generated by orchestrator
        description="Initial greeting (auto-generated by multi-agent system)"
    )


# Default configuration
default_config = AgentConfig()


# ============================================================================
# Multi-Agent Integration
# ============================================================================

def create_agent(config: AgentConfig | None = None) -> Agent:
    """
    Create and configure the LiveKit voice agent with multi-agent orchestration.
    
    The agent integrates multiple specialized person agents, each with:
    - Unique personality and backstory
    - Specialized topic knowledge (from separate FAISS collections)
    - Ability to hand off conversations to other experts
    
    Args:
        config: Optional AgentConfig instance. If None, uses default_config.
    
    Returns:
        Agent: Fully configured agent with multi-agent orchestration
    """
    if config is None:
        config = default_config
    
    # Initialize multi-agent RAG service
    logger.info("Initializing Multi-Agent RAG service...")
    try:
        multi_agent_service = get_multi_agent_rag_service()
        logger.info("âœ… Multi-Agent RAG service initialized")
        
        # Log all available agents
        people = multi_agent_service.get_all_people()
        logger.info(f"Available experts ({len(people)}):")
        for person in people:
            logger.info(f"  - {person.name}: {person.topic} ({person.personality_type})")
        
    except Exception as e:
        logger.error(f"âŒ Failed to initialize Multi-Agent RAG service: {e}")
        raise
    
    # Create chat context with a single generic system prompt
    chat_ctx = llm.ChatContext()
    system_prompt = (
        "You are facilitating a voice-agent networking mixer featuring three specialists:\n"
        "- Skye Morales (interruption)\n"
        "- Noah Reed (latency)\n"
        "- Avery Kim (streaming)\n\n"
        "The event stays focused on interruption management, latency, and streaming for live voice experiences. "
        "Handle light conversation yourself, but whenever the user asks anything technical or summons an expert, "
        "call the `query_networking_event` tool. Read the tool's response verbatimâ€”it already includes "
        "the speaker's backstory, personality, and topic-specific context."
    )
    chat_ctx.add_message(role="system", content=system_prompt)
    
    # Configure VAD model
    vad_model = silero.VAD.load(
        min_speech_duration=config.vad.min_speech_duration,
        min_silence_duration=config.vad.min_silence_duration,
        activation_threshold=config.vad.activation_threshold,
    )
    
    # Define the multi-agent query function tool
    @function_tool(
        name="query_networking_event",
        description="Query the networking event to get information from specialized experts. Use this when users ask questions about any topic - the system will automatically route to the right expert and handle handoffs between experts."
    )
    async def query_networking_event(query: str) -> str:
        """
        Query the multi-agent networking event system.
        
        Args:
            query: The user's question
        
        Returns:
            Response from the appropriate expert with context
        """
        try:
            # Get response from orchestrator
            result = multi_agent_service.query(query)
            
            if result["handoff"]:
                # Handoff occurred - return handoff message
                logger.info(f"ðŸ”„ Handoff: switching to {result['person']}")
                return result["handoff_message"]
            else:
                # Current person handles query
                person_obj = result["person_obj"]
                context = result["context"]
                
                persona_prompt = result.get("system_prompt", "")
                
                rag_context = context or "[No context retrieved]"
                response = f"""{persona_prompt}

[Context from {person_obj.name}'s knowledge base]
{rag_context}

[Instructions]
Using the context above, answer the user's question: "{query}"
Stay in character as {person_obj.name} with a {person_obj.personality_type} personality.
Make sure your tone reflects their backstory (e.g., Skye cracks jokes every time, Avery is curt and a little rude).
Integrate the context naturally without saying "the context says" or similar.
"""
                logger.info(
                    f"âœ… {person_obj.name} retrieved context ({len(context or '')} chars)"
                )
                return response
        
        except Exception as e:
            logger.error(f"âŒ Error querying multi-agent system: {e}")
            active_person = None
            excuse = (
                "Everyone's juggling another conversation right now."
            )
            try:
                active_person = multi_agent_service.get_current_person()
            except Exception:
                active_person = None
            if active_person:
                excuse = (
                    f"{active_person.name} just stepped away to help someone else"
                    "â€”probably ran to grab water or take a quick break."
                )
            return (
                f"{excuse} Give them a moment and feel free to ask again or"
                " check in with another expert."
            )
    
    # Create Agent with multi-agent tool
    agent = Agent(
        instructions=system_prompt,
        chat_ctx=chat_ctx,
        stt=config.stt.model,
        llm=config.llm.model,
        tts=config.tts.model,
        vad=vad_model,
        tools=[query_networking_event],
    )
    
    # Store multi-agent service on agent for reference
    agent._multi_agent_service = multi_agent_service
    logger.info("âœ… Multi-agent system integrated with LiveKit agent")
    
    return agent


def get_greeting_message(config: AgentConfig | None = None) -> str:
    """
    Get the initial greeting from the randomly selected person at the networking event.
    
    Args:
        config: Optional AgentConfig instance
    
    Returns:
        str: Personalized greeting from current person
    """
    try:
        multi_agent_service = get_multi_agent_rag_service()
        greeting = multi_agent_service.get_initial_greeting()
        return greeting
    except Exception as e:
        logger.error(f"Error getting greeting: {e}")
        return "Hello! Welcome to the networking event. How can I help you today?"